{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🍅 Tomato Segmentation Using U-Net\n",
    "\n",
    "##### This code falls under the Assignment 2 of the course GIT 1 @ College of Computing - UM6P. \n",
    "##### Done by: \n",
    "- BADDOU Mounia (@MTheCreator), \n",
    "- FRI Zyad (@ZyadFri), \n",
    "- KABLY Malak (@malakkbl), \n",
    "\n",
    "##### Academic year: 2024 / 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing first all needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaration of used datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to your dataset folders\n",
    "dataset_path = \"Tomato_dataset\"\n",
    "train_path = os.path.join(dataset_path, \"Train\")\n",
    "train2_path = os.path.join(dataset_path, \"Train2\")\n",
    "mask_path = os.path.join(dataset_path, \"Mask\")\n",
    "mask2_path = os.path.join(dataset_path, \"Mask2\")\n",
    "test_path = os.path.join(dataset_path, \"Test\")\n",
    "test2_path = os.path.join(dataset_path, \"Test2\")\n",
    "\n",
    "# Image size - smaller size for faster training on CPU\n",
    "IMG_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the handler class of our tomato data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TomatoDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading tomato images and their segmentation masks\"\"\"\n",
    "    \n",
    "    def __init__(self, img_dir, mask_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_dir (string): Directory with all the images\n",
    "            mask_dir (string): Directory with all the masks\n",
    "            transform (callable, optional): Optional transform to be applied on a sample\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get list of files in both directories\n",
    "        self.img_names = sorted([f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "        self.mask_names = sorted([f for f in os.listdir(mask_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "        \n",
    "        # Handle the case where the number of images and masks don't match\n",
    "        if len(self.img_names) != len(self.mask_names):\n",
    "            print(f\"Warning: Number of images ({len(self.img_names)}) doesn't match number of masks ({len(self.mask_names)})\")\n",
    "            print(\"Will use the minimum number of files and assume they correspond to each other.\")\n",
    "            \n",
    "            # Use only the common part based on filenames or indices\n",
    "            if len(self.img_names) > len(self.mask_names):\n",
    "                self.img_names = self.img_names[:len(self.mask_names)]\n",
    "            else:\n",
    "                self.mask_names = self.mask_names[:len(self.img_names)]\n",
    "            \n",
    "            print(f\"Adjusted dataset size: {len(self.img_names)} images and masks\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = os.path.join(self.img_dir, self.img_names[idx])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        \n",
    "        # Load mask\n",
    "        mask_name = os.path.join(self.mask_dir, self.mask_names[idx])\n",
    "        mask = Image.open(mask_name).convert(\"L\")  # Convert to grayscale\n",
    "        \n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "        \n",
    "        # Normalize the mask to binary (0 for background, 1 for tomato)\n",
    "        mask = (mask > 0.5).float()\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the model, its architecture and its meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the U-Net model architecture\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        \"\"\"\n",
    "        U-Net architecture with fewer features for CPU efficiency\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels (3 for RGB)\n",
    "            out_channels (int): Number of output channels (1 for binary segmentation)\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # Encoder (downsampling)\n",
    "        # Using smaller feature maps than typical U-Net for CPU efficiency\n",
    "        self.enc1 = self._double_conv(in_channels, 32)  # Original U-Net uses 64\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.enc2 = self._double_conv(32, 64)  # Original uses 128\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.enc3 = self._double_conv(64, 128)  # Original uses 256\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.enc4 = self._double_conv(128, 256)  # Original uses 512\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = self._double_conv(256, 512)  # Original uses 1024\n",
    "        \n",
    "        # Decoder (upsampling)\n",
    "        self.up_conv4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec4 = self._double_conv(512, 256)  # 512 = 256 (from up_conv4) + 256 (skip connection from enc4)\n",
    "        \n",
    "        self.up_conv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec3 = self._double_conv(256, 128)  # 256 = 128 (from up_conv3) + 128 (skip connection from enc3)\n",
    "        \n",
    "        self.up_conv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec2 = self._double_conv(128, 64)  # 128 = 64 (from up_conv2) + 64 (skip connection from enc2)\n",
    "        \n",
    "        self.up_conv1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.dec1 = self._double_conv(64, 32)  # 64 = 32 (from up_conv1) + 32 (skip connection from enc1)\n",
    "        \n",
    "        # Output layer\n",
    "        self.out_conv = nn.Conv2d(32, out_channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def _double_conv(self, in_channels, out_channels):\n",
    "        \"\"\"Helper function for creating double convolution blocks\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder path\n",
    "        enc1_out = self.enc1(x)\n",
    "        enc2_out = self.enc2(self.pool1(enc1_out))\n",
    "        enc3_out = self.enc3(self.pool2(enc2_out))\n",
    "        enc4_out = self.enc4(self.pool3(enc3_out))\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck_out = self.bottleneck(self.pool4(enc4_out))\n",
    "        \n",
    "        # Decoder path with skip connections\n",
    "        dec4_out = self.up_conv4(bottleneck_out)\n",
    "        # Ensure dimensions match before concatenation (may be necessary if odd dimensions)\n",
    "        if dec4_out.shape != enc4_out.shape[0:2]:\n",
    "            enc4_out = enc4_out[:, :, :dec4_out.shape[2], :dec4_out.shape[3]]\n",
    "        dec4_out = self.dec4(torch.cat([dec4_out, enc4_out], dim=1))\n",
    "        \n",
    "        dec3_out = self.up_conv3(dec4_out)\n",
    "        # Ensure dimensions match\n",
    "        if dec3_out.shape[2:] != enc3_out.shape[2:]:\n",
    "            enc3_out = enc3_out[:, :, :dec3_out.shape[2], :dec3_out.shape[3]]\n",
    "        dec3_out = self.dec3(torch.cat([dec3_out, enc3_out], dim=1))\n",
    "        \n",
    "        dec2_out = self.up_conv2(dec3_out)\n",
    "        # Ensure dimensions match\n",
    "        if dec2_out.shape[2:] != enc2_out.shape[2:]:\n",
    "            enc2_out = enc2_out[:, :, :dec2_out.shape[2], :dec2_out.shape[3]]\n",
    "        dec2_out = self.dec2(torch.cat([dec2_out, enc2_out], dim=1))\n",
    "        \n",
    "        dec1_out = self.up_conv1(dec2_out)\n",
    "        # Ensure dimensions match\n",
    "        if dec1_out.shape[2:] != enc1_out.shape[2:]:\n",
    "            enc1_out = enc1_out[:, :, :dec1_out.shape[2], :dec1_out.shape[3]]\n",
    "        dec1_out = self.dec1(torch.cat([dec1_out, enc1_out], dim=1))\n",
    "        \n",
    "        # Output layer\n",
    "        out = self.out_conv(dec1_out)\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of helper functions in treating the images according to what was seen in the course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and preprocessing\n",
    "def get_transforms():\n",
    "    \"\"\"Define transformations for images and masks\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        # Only normalize the images, not the masks\n",
    "    ])\n",
    "    \n",
    "    return transform\n",
    "\n",
    "# Dice coefficient for evaluation\n",
    "def dice_coefficient(pred, target):\n",
    "    \"\"\"\n",
    "    Calculate the Dice coefficient between prediction and target\n",
    "    \n",
    "    Args:\n",
    "        pred (torch.Tensor): Predicted binary mask\n",
    "        target (torch.Tensor): Ground truth binary mask\n",
    "    \n",
    "    Returns:\n",
    "        float: Dice coefficient value\n",
    "    \"\"\"\n",
    "    smooth = 1e-5  # To avoid division by zero\n",
    "    \n",
    "    # Flatten the tensors\n",
    "    pred_flat = pred.view(-1)\n",
    "    target_flat = target.view(-1)\n",
    "    \n",
    "    # Calculate intersection and union\n",
    "    intersection = (pred_flat * target_flat).sum()\n",
    "    union = pred_flat.sum() + target_flat.sum()\n",
    "    \n",
    "    # Calculate Dice coefficient\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    return dice.item()\n",
    "\n",
    "# IoU (Intersection over Union) / Jaccard Index\n",
    "def iou_score(pred, target):\n",
    "    \"\"\"\n",
    "    Calculate IoU (Intersection over Union) between prediction and target\n",
    "    \n",
    "    Args:\n",
    "        pred (torch.Tensor): Predicted binary mask\n",
    "        target (torch.Tensor): Ground truth binary mask\n",
    "    \n",
    "    Returns:\n",
    "        float: IoU score\n",
    "    \"\"\"\n",
    "    smooth = 1e-5\n",
    "    \n",
    "    # Flatten the tensors\n",
    "    pred_flat = pred.view(-1)\n",
    "    target_flat = target.view(-1)\n",
    "    \n",
    "    # Calculate intersection and union\n",
    "    intersection = (pred_flat * target_flat).sum()\n",
    "    union = pred_flat.sum() + target_flat.sum() - intersection\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    \n",
    "    return iou.item()\n",
    "\n",
    "\n",
    "def visualize_prediction(image, true_mask, pred_mask, idx=0, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize original image, ground truth mask, and predicted mask\n",
    "    \n",
    "    Args:\n",
    "        image (torch.Tensor): Input image\n",
    "        true_mask (torch.Tensor): Ground truth mask\n",
    "        pred_mask (torch.Tensor): Predicted mask\n",
    "        idx (int): Sample index\n",
    "        save_path (str): Path to save the visualization\n",
    "    \"\"\"\n",
    "    # Convert tensors to numpy arrays\n",
    "    img = image.permute(1, 2, 0).cpu().numpy()\n",
    "    true_mask = true_mask.squeeze().cpu().numpy()\n",
    "    pred_mask = pred_mask.squeeze().cpu().numpy()\n",
    "    \n",
    "    # Create a figure with 3 subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Plot original image\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "    \n",
    "    # Plot ground truth mask\n",
    "    axes[1].imshow(true_mask, cmap=\"gray\")\n",
    "    axes[1].set_title(\"Ground Truth Mask\")\n",
    "    axes[1].axis(\"off\")\n",
    "    \n",
    "    # Plot predicted mask\n",
    "    axes[2].imshow(pred_mask, cmap=\"gray\")\n",
    "    axes[2].set_title(f\"Predicted Mask\\nDice: {dice_coefficient(torch.tensor(pred_mask), torch.tensor(true_mask)):.4f}\")\n",
    "    axes[2].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Training and Evaluating functions of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Train the U-Net model\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): U-Net model\n",
    "        train_loader (DataLoader): Training data loader\n",
    "        val_loader (DataLoader): Validation data loader\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer\n",
    "        num_epochs (int): Number of training epochs\n",
    "        device (str): Device to train on ('cpu' or 'cuda')\n",
    "    \n",
    "    Returns:\n",
    "        model: Trained model\n",
    "        dict: Training history (loss, accuracy, etc.)\n",
    "    \"\"\"\n",
    "    # Initialize variables to store metrics\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_dice': [],\n",
    "        'val_dice': [],\n",
    "        'train_iou': [],\n",
    "        'val_iou': []\n",
    "    }\n",
    "    \n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_dice = 0.0\n",
    "        train_iou = 0.0\n",
    "        \n",
    "        # Use tqdm for progress bar\n",
    "        for images, masks in tqdm(train_loader, desc=\"Training\"):\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update metrics\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Convert predictions to binary (0 or 1)\n",
    "            preds = (outputs > 0.5).float()\n",
    "            \n",
    "            # Calculate Dice coefficient and IoU\n",
    "            train_dice += dice_coefficient(preds, masks)\n",
    "            train_iou += iou_score(preds, masks)\n",
    "        \n",
    "        # Calculate average metrics for this epoch\n",
    "        train_loss /= len(train_loader)\n",
    "        train_dice /= len(train_loader)\n",
    "        train_iou /= len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_dice = 0.0\n",
    "        val_iou = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in tqdm(val_loader, desc=\"Validation\"):\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                preds = (outputs > 0.5).float()\n",
    "                val_dice += dice_coefficient(preds, masks)\n",
    "                val_iou += iou_score(preds, masks)\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_dice /= len(val_loader)\n",
    "        val_iou /= len(val_loader)\n",
    "        \n",
    "        # Store metrics in history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_dice'].append(train_dice)\n",
    "        history['val_dice'].append(val_dice)\n",
    "        history['train_iou'].append(train_iou)\n",
    "        history['val_iou'].append(val_iou)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"Train Dice: {train_dice:.4f}, Val Dice: {val_dice:.4f}\")\n",
    "        print(f\"Train IoU: {train_iou:.4f}, Val IoU: {val_iou:.4f}\")\n",
    "        \n",
    "        # Print estimated time remaining\n",
    "        elapsed_time = time.time() - start_time\n",
    "        estimated_total_time = elapsed_time * num_epochs / (epoch + 1)\n",
    "        estimated_remaining_time = estimated_total_time - elapsed_time\n",
    "        print(f\"Elapsed time: {elapsed_time/60:.2f} min, Est. remaining: {estimated_remaining_time/60:.2f} min\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Total training time\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Total training time: {total_time/60:.2f} minutes\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model on test data\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained U-Net model\n",
    "        test_loader (DataLoader): Test data loader\n",
    "        criterion: Loss function\n",
    "        device (str): Device to evaluate on ('cpu' or 'cuda')\n",
    "    \n",
    "    Returns:\n",
    "        dict: Evaluation metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_dice = 0.0\n",
    "    test_iou = 0.0\n",
    "    \n",
    "    # Lists to store images and masks for visualization\n",
    "    test_images = []\n",
    "    test_true_masks = []\n",
    "    test_pred_masks = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            preds = (outputs > 0.5).float()\n",
    "            test_dice += dice_coefficient(preds, masks)\n",
    "            test_iou += iou_score(preds, masks)\n",
    "            \n",
    "            # Store some samples for visualization (first 5)\n",
    "            if len(test_images) < 5:\n",
    "                test_images.append(images[0])\n",
    "                test_true_masks.append(masks[0])\n",
    "                test_pred_masks.append(preds[0])\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    test_dice /= len(test_loader)\n",
    "    test_iou /= len(test_loader)\n",
    "    \n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Dice: {test_dice:.4f}\")\n",
    "    print(f\"Test IoU: {test_iou:.4f}\")\n",
    "    \n",
    "    # Create output directory for visualizations\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    \n",
    "    # Visualize predictions\n",
    "    for i in range(len(test_images)):\n",
    "        visualize_prediction(\n",
    "            test_images[i], \n",
    "            test_true_masks[i], \n",
    "            test_pred_masks[i], \n",
    "            idx=i, \n",
    "            save_path=f\"results/prediction_{i}.png\"\n",
    "        )\n",
    "    \n",
    "    return {\n",
    "        'loss': test_loss,\n",
    "        'dice': test_dice,\n",
    "        'iou': test_iou,\n",
    "        'images': test_images,\n",
    "        'true_masks': test_true_masks,\n",
    "        'pred_masks': test_pred_masks\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function responsible to plot our output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training history\n",
    "    \n",
    "    Args:\n",
    "        history (dict): Training history dictionary\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot Dice coefficient\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_dice'], label='Train Dice')\n",
    "    plt.plot(history['val_dice'], label='Validation Dice')\n",
    "    plt.title('Dice Coefficient')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Dice')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/training_history.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot IoU\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history['train_iou'], label='Train IoU')\n",
    "    plt.plot(history['val_iou'], label='Validation IoU')\n",
    "    plt.title('IoU Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/iou_history.png\")\n",
    "    plt.close()\n",
    "\n",
    "def segment_new_image(model, image_path, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Segment a new unseen image\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained U-Net model\n",
    "        image_path (str): Path to the image\n",
    "        device (str): Device to run on ('cpu' or 'cuda')\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Original image\n",
    "        numpy.ndarray: Segmented mask\n",
    "    \"\"\"\n",
    "    # Load and preprocess the image\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    original_size = image.size\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        pred_mask = (output > 0.5).float()\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    image_np = image_tensor.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "    mask_np = pred_mask.squeeze().cpu().numpy()\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_np)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask_np, cmap=\"gray\")\n",
    "    plt.title(\"Segmented Mask\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/new_image_segmentation.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    return image_np, mask_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function to orchestrate the use of everything defined beforehands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading datasets...\n",
      "Warning: Number of images (80) doesn't match number of masks (20)\n",
      "Will use the minimum number of files and assume they correspond to each other.\n",
      "Adjusted dataset size: 20 images and masks\n",
      "Warning: Number of images (20) doesn't match number of masks (80)\n",
      "Will use the minimum number of files and assume they correspond to each other.\n",
      "Adjusted dataset size: 20 images and masks\n",
      "Train dataset size: 80\n",
      "Validation dataset size: 20\n",
      "Test dataset size: 40\n",
      "Sample image shape: torch.Size([4, 3, 256, 256])\n",
      "Sample mask shape: torch.Size([4, 1, 256, 256])\n",
      "UNet(\n",
      "  (enc1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (enc2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (enc3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (enc4): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bottleneck): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (up_conv4): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (dec4): Sequential(\n",
      "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (up_conv3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (dec3): Sequential(\n",
      "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (up_conv2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (dec2): Sequential(\n",
      "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (up_conv1): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (dec1): Sequential(\n",
      "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (out_conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Training for 20 epochs on cpu...\n",
      "Note: This will take several hours on CPU. Consider reducing the number of epochs or image size.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:31<00:00,  1.59s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4004, Val Loss: 0.4188\n",
      "Train Dice: 0.7820, Val Dice: 0.5602\n",
      "Train IoU: 0.6691, Val IoU: 0.3990\n",
      "Elapsed time: 0.57 min, Est. remaining: 10.91 min\n",
      "--------------------------------------------------\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:31<00:00,  1.59s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3036, Val Loss: 0.2633\n",
      "Train Dice: 0.8207, Val Dice: 0.8350\n",
      "Train IoU: 0.7129, Val IoU: 0.7230\n",
      "Elapsed time: 1.15 min, Est. remaining: 10.32 min\n",
      "--------------------------------------------------\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:32<00:00,  1.63s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2564, Val Loss: 0.2144\n",
      "Train Dice: 0.8384, Val Dice: 0.8821\n",
      "Train IoU: 0.7306, Val IoU: 0.7930\n",
      "Elapsed time: 1.74 min, Est. remaining: 9.84 min\n",
      "--------------------------------------------------\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:33<00:00,  1.69s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2352, Val Loss: 0.1930\n",
      "Train Dice: 0.8167, Val Dice: 0.8837\n",
      "Train IoU: 0.7094, Val IoU: 0.7956\n",
      "Elapsed time: 2.35 min, Est. remaining: 9.39 min\n",
      "--------------------------------------------------\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:32<00:00,  1.62s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2142, Val Loss: 0.1922\n",
      "Train Dice: 0.8235, Val Dice: 0.8777\n",
      "Train IoU: 0.7112, Val IoU: 0.7859\n",
      "Elapsed time: 2.93 min, Est. remaining: 8.79 min\n",
      "--------------------------------------------------\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:32<00:00,  1.60s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1956, Val Loss: 0.1705\n",
      "Train Dice: 0.8267, Val Dice: 0.8821\n",
      "Train IoU: 0.7177, Val IoU: 0.7937\n",
      "Elapsed time: 3.51 min, Est. remaining: 8.19 min\n",
      "--------------------------------------------------\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:30<00:00,  1.54s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1843, Val Loss: 0.1601\n",
      "Train Dice: 0.8300, Val Dice: 0.8844\n",
      "Train IoU: 0.7299, Val IoU: 0.7972\n",
      "Elapsed time: 4.07 min, Est. remaining: 7.55 min\n",
      "--------------------------------------------------\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:30<00:00,  1.51s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1804, Val Loss: 0.1431\n",
      "Train Dice: 0.8259, Val Dice: 0.8833\n",
      "Train IoU: 0.7213, Val IoU: 0.7950\n",
      "Elapsed time: 4.61 min, Est. remaining: 6.92 min\n",
      "--------------------------------------------------\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:30<00:00,  1.54s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1726, Val Loss: 0.1486\n",
      "Train Dice: 0.8298, Val Dice: 0.8748\n",
      "Train IoU: 0.7222, Val IoU: 0.7826\n",
      "Elapsed time: 5.17 min, Est. remaining: 6.32 min\n",
      "--------------------------------------------------\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:30<00:00,  1.51s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1695, Val Loss: 0.1395\n",
      "Train Dice: 0.8191, Val Dice: 0.8816\n",
      "Train IoU: 0.7091, Val IoU: 0.7922\n",
      "Elapsed time: 5.71 min, Est. remaining: 5.71 min\n",
      "--------------------------------------------------\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:30<00:00,  1.53s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1609, Val Loss: 0.1418\n",
      "Train Dice: 0.8328, Val Dice: 0.8832\n",
      "Train IoU: 0.7236, Val IoU: 0.7954\n",
      "Elapsed time: 6.27 min, Est. remaining: 5.13 min\n",
      "--------------------------------------------------\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:30<00:00,  1.54s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1613, Val Loss: 0.1483\n",
      "Train Dice: 0.8260, Val Dice: 0.8757\n",
      "Train IoU: 0.7194, Val IoU: 0.7835\n",
      "Elapsed time: 6.82 min, Est. remaining: 4.55 min\n",
      "--------------------------------------------------\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:31<00:00,  1.55s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1600, Val Loss: 0.1499\n",
      "Train Dice: 0.8207, Val Dice: 0.8705\n",
      "Train IoU: 0.7104, Val IoU: 0.7763\n",
      "Elapsed time: 7.38 min, Est. remaining: 3.98 min\n",
      "--------------------------------------------------\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:30<00:00,  1.52s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1494, Val Loss: 0.1624\n",
      "Train Dice: 0.8418, Val Dice: 0.8407\n",
      "Train IoU: 0.7381, Val IoU: 0.7291\n",
      "Elapsed time: 7.94 min, Est. remaining: 3.40 min\n",
      "--------------------------------------------------\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:31<00:00,  1.56s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1602, Val Loss: 0.3508\n",
      "Train Dice: 0.8271, Val Dice: 0.8350\n",
      "Train IoU: 0.7131, Val IoU: 0.7192\n",
      "Elapsed time: 8.50 min, Est. remaining: 2.83 min\n",
      "--------------------------------------------------\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:30<00:00,  1.55s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1557, Val Loss: 0.1407\n",
      "Train Dice: 0.8313, Val Dice: 0.8839\n",
      "Train IoU: 0.7251, Val IoU: 0.7960\n",
      "Elapsed time: 9.06 min, Est. remaining: 2.26 min\n",
      "--------------------------------------------------\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:31<00:00,  1.56s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1514, Val Loss: 0.1366\n",
      "Train Dice: 0.8345, Val Dice: 0.8781\n",
      "Train IoU: 0.7277, Val IoU: 0.7869\n",
      "Elapsed time: 9.62 min, Est. remaining: 1.70 min\n",
      "--------------------------------------------------\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:31<00:00,  1.56s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1546, Val Loss: 0.1297\n",
      "Train Dice: 0.8252, Val Dice: 0.8812\n",
      "Train IoU: 0.7130, Val IoU: 0.7921\n",
      "Elapsed time: 10.19 min, Est. remaining: 1.13 min\n",
      "--------------------------------------------------\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:31<00:00,  1.55s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1528, Val Loss: 0.1495\n",
      "Train Dice: 0.8277, Val Dice: 0.8843\n",
      "Train IoU: 0.7241, Val IoU: 0.7966\n",
      "Elapsed time: 10.75 min, Est. remaining: 0.57 min\n",
      "--------------------------------------------------\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:31<00:00,  1.56s/it]\n",
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1451, Val Loss: 0.1274\n",
      "Train Dice: 0.8366, Val Dice: 0.8837\n",
      "Train IoU: 0.7367, Val IoU: 0.7959\n",
      "Elapsed time: 11.31 min, Est. remaining: 0.00 min\n",
      "--------------------------------------------------\n",
      "Total training time: 11.31 minutes\n",
      "Evaluating on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 10/10 [00:05<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2280\n",
      "Test Dice: 0.7720\n",
      "Test IoU: 0.6576\n",
      "Model saved successfully.\n",
      "Segmenting a test image...\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Check if GPU is available\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create transformations\n",
    "    transform = get_transforms()\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"Loading datasets...\")\n",
    "    \n",
    "    # Load training images from both Train and Train2 folders with their corresponding masks\n",
    "    train_dataset1 = TomatoDataset(\n",
    "        img_dir=train_path,\n",
    "        mask_dir=mask_path,\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    train_dataset2 = TomatoDataset(\n",
    "        img_dir=train2_path,\n",
    "        mask_dir=mask2_path,\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    # Combine both training datasets\n",
    "    full_train_dataset = torch.utils.data.ConcatDataset([train_dataset1, train_dataset2])\n",
    "    \n",
    "    # Split into train and validation (80/20 split)\n",
    "    train_size = int(0.8 * len(full_train_dataset))\n",
    "    val_size = len(full_train_dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_train_dataset, [train_size, val_size]\n",
    "    )\n",
    "    \n",
    "    # Load test datasets from both Test and Test2 folders\n",
    "    test_dataset1 = TomatoDataset(\n",
    "        img_dir=test_path,\n",
    "        mask_dir=mask_path,  # Using Mask for Test folder\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    test_dataset2 = TomatoDataset(\n",
    "        img_dir=test2_path,\n",
    "        mask_dir=mask2_path,  # Using Mask2 for Test2 folder\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    # Combine both test datasets\n",
    "    test_dataset = torch.utils.data.ConcatDataset([test_dataset1, test_dataset2])\n",
    "    \n",
    "    print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "    print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "    \n",
    "    # Use smaller batch size for CPU training\n",
    "    batch_size = 4\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Display a sample from the training set\n",
    "    sample_img, sample_mask = next(iter(train_loader))\n",
    "    print(f\"Sample image shape: {sample_img.shape}\")\n",
    "    print(f\"Sample mask shape: {sample_mask.shape}\")\n",
    "    \n",
    "    # Visualize a sample\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(sample_img[0].permute(1, 2, 0).numpy())\n",
    "    plt.title(\"Sample Image\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(sample_mask[0].squeeze().numpy(), cmap=\"gray\")\n",
    "    plt.title(\"Sample Mask\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    plt.savefig(\"results/sample_data.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Create U-Net model\n",
    "    model = UNet(in_channels=3, out_channels=1).to(device)\n",
    "    print(model)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    # Using BCELoss for binary segmentation\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Using Adam optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Train the model (reduced epochs for CPU training)\n",
    "    num_epochs = 20\n",
    "    print(f\"Training for {num_epochs} epochs on {device}...\")\n",
    "    print(\"Note: This will take several hours on CPU. Consider reducing the number of epochs or image size.\")\n",
    "    \n",
    "    trained_model, history = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, \n",
    "        num_epochs=num_epochs, device=device\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # Evaluate on test dataset\n",
    "    print(\"Evaluating on test dataset...\")\n",
    "    test_results = evaluate_model(trained_model, test_loader, criterion, device=device)\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(trained_model.state_dict(), \"results/tomato_unet_model.pth\")\n",
    "    print(\"Model saved successfully.\")\n",
    "    \n",
    "    # If any test images are available in the Test folder, segment them\n",
    "    test_files = [f for f in os.listdir(test_path) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    if test_files:\n",
    "        print(\"Segmenting a test image...\")\n",
    "        test_img_path = os.path.join(test_path, test_files[0])\n",
    "        segment_new_image(trained_model, test_img_path, device=device)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
